{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8Ulp8qkFSOkp",
        "outputId": "023d9008-6944-4bcd-e773-2507ba8b0185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aiohttp==3.8.3 (from -r requirements.txt (line 1))\n",
            "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal==1.3.1 (from -r requirements.txt (line 2))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting appnope==0.1.3 (from -r requirements.txt (line 3))\n",
            "  Downloading appnope-0.1.3-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting asttokens==2.2.1 (from -r requirements.txt (line 4))\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout==4.0.2 (from -r requirements.txt (line 5))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting attrs==22.2.0 (from -r requirements.txt (line 6))\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.11.1 (from -r requirements.txt (line 8))\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blobfile==2.0.1 (from -r requirements.txt (line 9))\n",
            "  Downloading blobfile-2.0.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4==0.0.1 (from -r requirements.txt (line 10))\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2022.12.7)\n",
            "Collecting charset-normalizer==2.1.1 (from -r requirements.txt (line 12))\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting comm==0.1.2 (from -r requirements.txt (line 13))\n",
            "  Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: contourpy==1.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.0.7)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.11.0)\n",
            "Collecting debugpy==1.6.5 (from -r requirements.txt (line 16))\n",
            "  Downloading debugpy-1.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==5.1.1 (from -r requirements.txt (line 17))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting docopt==0.6.2 (from -r requirements.txt (line 18))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.4)\n",
            "Collecting executing==1.2.0 (from -r requirements.txt (line 20))\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting filelock==3.9.0 (from -r requirements.txt (line 21))\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting fonttools==4.38.0 (from -r requirements.txt (line 22))\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist==1.3.3 (from -r requirements.txt (line 23))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.11.1 (from -r requirements.txt (line 24))\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (3.4)\n",
            "Collecting ipykernel==6.20.1 (from -r requirements.txt (line 26))\n",
            "  Downloading ipykernel-6.20.1-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.8.0 (from -r requirements.txt (line 27))\n",
            "  Downloading ipython-8.8.0-py3-none-any.whl (775 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.8/775.8 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi==0.18.2 (from -r requirements.txt (line 28))\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (1.2.0)\n",
            "Collecting jupyter_client==7.4.8 (from -r requirements.txt (line 30))\n",
            "  Downloading jupyter_client-7.4.8-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_core==5.1.3 (from -r requirements.txt (line 31))\n",
            "  Downloading jupyter_core-5.1.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.4.4)\n",
            "Requirement already satisfied: lxml==4.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (4.9.2)\n",
            "Collecting matplotlib==3.6.3 (from -r requirements.txt (line 34))\n",
            "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (0.1.6)\n",
            "Collecting multidict==6.0.4 (from -r requirements.txt (line 36))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (1.5.6)\n",
            "Collecting numpy==1.24.1 (from -r requirements.txt (line 38))\n",
            "  Downloading numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.26.1 (from -r requirements.txt (line 39))\n",
            "  Downloading openai-0.26.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==23.0 (from -r requirements.txt (line 40))\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.2 (from -r requirements.txt (line 41))\n",
            "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (0.8.3)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (0.7.5)\n",
            "Collecting Pillow==9.4.0 (from -r requirements.txt (line 45))\n",
            "  Downloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pipreqs==0.4.11 (from -r requirements.txt (line 46))\n",
            "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
            "Collecting platformdirs==2.6.2 (from -r requirements.txt (line 47))\n",
            "  Downloading platformdirs-2.6.2-py3-none-any.whl (14 kB)\n",
            "Collecting plotly==5.12.0 (from -r requirements.txt (line 48))\n",
            "  Downloading plotly-5.12.0-py2.py3-none-any.whl (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.36 (from -r requirements.txt (line 49))\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.9.4 (from -r requirements.txt (line 50))\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 52))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pycryptodomex==3.17 (from -r requirements.txt (line 53))\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pygments==2.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (2.14.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 55)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (2022.7.1)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (6.0)\n",
            "Collecting pyzmq==24.0.1 (from -r requirements.txt (line 59))\n",
            "  Downloading pyzmq-24.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (2022.10.31)\n",
            "Collecting requests==2.28.1 (from -r requirements.txt (line 61))\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.0 (from -r requirements.txt (line 62))\n",
            "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m153.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.0 (from -r requirements.txt (line 63))\n",
            "  Downloading scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 64)) (1.16.0)\n",
            "Collecting soupsieve==2.3.2.post1 (from -r requirements.txt (line 65))\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting stack-data==0.6.2 (from -r requirements.txt (line 66))\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting tenacity==8.1.0 (from -r requirements.txt (line 67))\n",
            "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (3.1.0)\n",
            "Collecting tiktoken==0.1.2 (from -r requirements.txt (line 69))\n",
            "  Downloading tiktoken-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.13.2 (from -r requirements.txt (line 70))\n",
            "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado==6.2 (from -r requirements.txt (line 71))\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r requirements.txt (line 72))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets==5.8.1 (from -r requirements.txt (line 73))\n",
            "  Downloading traitlets-5.8.1-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.25.1 (from -r requirements.txt (line 74))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m141.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.4.0 (from -r requirements.txt (line 75))\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3==1.26.13 (from -r requirements.txt (line 76))\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth==0.2.5 (from -r requirements.txt (line 77))\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting yarg==0.1.9 (from -r requirements.txt (line 78))\n",
            "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
            "Collecting yarl==1.8.2 (from -r requirements.txt (line 79))\n",
            "  Downloading yarl-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bs4, docopt, openai\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=24002019a9e2d22044aadf8b0437d88a05aab25ee8647c3e1c0a70bade8b2889\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=670a7ab894508b57666059fc75066f69daa375fc871080d15ea16c624d5b1c80\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.1-py3-none-any.whl size=67293 sha256=14f74159d76e4cd3157a956b3444ae07bfd721a88c81fce2650ced99af7e15e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/cc/20/ba0ee3af9dddcdaa3496652087be11b09f28956640528bd7c6\n",
            "Successfully built bs4 docopt openai\n",
            "Installing collected packages: wcwidth, tokenizers, pure-eval, executing, docopt, appnope, urllib3, typing_extensions, traitlets, tqdm, tornado, tenacity, soupsieve, pyzmq, pycryptodomex, psutil, prompt-toolkit, platformdirs, Pillow, packaging, numpy, multidict, jedi, frozenlist, fonttools, filelock, decorator, debugpy, charset-normalizer, attrs, async-timeout, asttokens, yarl, stack-data, scipy, requests, plotly, pandas, jupyter_core, comm, blobfile, beautifulsoup4, aiosignal, yarg, tiktoken, scikit-learn, matplotlib, jupyter_client, ipython, huggingface-hub, bs4, aiohttp, transformers, pipreqs, openai, ipykernel\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.6\n",
            "    Uninstalling wcwidth-0.2.6:\n",
            "      Successfully uninstalled wcwidth-0.2.6\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.1\n",
            "    Uninstalling tornado-6.3.1:\n",
            "      Successfully uninstalled tornado-6.3.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.2.2\n",
            "    Uninstalling tenacity-8.2.2:\n",
            "      Successfully uninstalled tenacity-8.2.2\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.4.1\n",
            "    Uninstalling soupsieve-2.4.1:\n",
            "      Successfully uninstalled soupsieve-2.4.1\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.38\n",
            "    Uninstalling prompt-toolkit-3.0.38:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.38\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 3.3.0\n",
            "    Uninstalling platformdirs-3.3.0:\n",
            "      Successfully uninstalled platformdirs-3.3.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.39.3\n",
            "    Uninstalling fonttools-4.39.3:\n",
            "      Successfully uninstalled fonttools-4.39.3\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.12.0\n",
            "    Uninstalling filelock-3.12.0:\n",
            "      Successfully uninstalled filelock-3.12.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: debugpy\n",
            "    Found existing installation: debugpy 1.6.6\n",
            "    Uninstalling debugpy-1.6.6:\n",
            "      Successfully uninstalled debugpy-1.6.6\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.13.1\n",
            "    Uninstalling plotly-5.13.1:\n",
            "      Successfully uninstalled plotly-5.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: jupyter_core\n",
            "    Found existing installation: jupyter_core 5.3.0\n",
            "    Uninstalling jupyter_core-5.3.0:\n",
            "      Successfully uninstalled jupyter_core-5.3.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jupyter_client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.20.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.8.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.28.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado==6.3.1, but you have tornado 6.2 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 aiohttp-3.8.3 aiosignal-1.3.1 appnope-0.1.3 asttokens-2.2.1 async-timeout-4.0.2 attrs-22.2.0 beautifulsoup4-4.11.1 blobfile-2.0.1 bs4-0.0.1 charset-normalizer-2.1.1 comm-0.1.2 debugpy-1.6.5 decorator-5.1.1 docopt-0.6.2 executing-1.2.0 filelock-3.9.0 fonttools-4.38.0 frozenlist-1.3.3 huggingface-hub-0.11.1 ipykernel-6.20.1 ipython-8.8.0 jedi-0.18.2 jupyter_client-7.4.8 jupyter_core-5.1.3 matplotlib-3.6.3 multidict-6.0.4 numpy-1.24.1 openai-0.26.1 packaging-23.0 pandas-1.5.2 pipreqs-0.4.11 platformdirs-2.6.2 plotly-5.12.0 prompt-toolkit-3.0.36 psutil-5.9.4 pure-eval-0.2.2 pycryptodomex-3.17 pyzmq-24.0.1 requests-2.28.1 scikit-learn-1.2.0 scipy-1.10.0 soupsieve-2.3.2.post1 stack-data-0.6.2 tenacity-8.1.0 tiktoken-0.1.2 tokenizers-0.13.2 tornado-6.2 tqdm-4.64.1 traitlets-5.8.1 transformers-4.25.1 typing_extensions-4.4.0 urllib3-1.26.13 wcwidth-0.2.5 yarg-0.1.9 yarl-1.8.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "debugpy",
                  "decorator",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "prompt_toolkit",
                  "psutil",
                  "tornado",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "r5RI7BCtRuox",
        "outputId": "a4959b6e-2224-4797-9870-ef13dfee6cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://economictimes.indiatimes.com/topic/crude-oil-prices\n",
            "https://economictimes.indiatimes.com/markets/why-is-crude-oil-price-falling\n",
            "https://economictimes.indiatimes.com/markets/commodities/news/crude-oil-prices-fall-as-us-gasoline-stocks-rise-for-a-fifth-week/articleshow/82423271.cms\n",
            "https://economictimes.indiatimes.com/markets/commodities/news/crude-oil-prices-fall-as-us-gasoline-stocks-rise-for-a-fifth-week/printarticle/82423271.cms\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d2985d1406cd>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-d2985d1406cd>\u001b[0m in \u001b[0;36mcrawl\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# Get the text from the URL using BeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Get the text but remove the tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from html.parser import HTMLParser\n",
        "from urllib.parse import urlparse\n",
        "import os\n",
        "\n",
        "# Regex pattern to match a URL\n",
        "HTTP_URL_PATTERN = r'^http[s]*://.+'\n",
        "\n",
        "# Define root domain to crawl\n",
        "domain = \"economictimes.indiatimes.com\"\n",
        "full_url = \"https://economictimes.indiatimes.com/topic/crude-oil-prices\"\n",
        "\n",
        "# Create a class to parse the HTML and get the hyperlinks\n",
        "class HyperlinkParser(HTMLParser):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Create a list to store the hyperlinks\n",
        "        self.hyperlinks = []\n",
        "\n",
        "    # Override the HTMLParser's handle_starttag method to get the hyperlinks\n",
        "    def handle_starttag(self, tag, attrs):\n",
        "        attrs = dict(attrs)\n",
        "\n",
        "        # If the tag is an anchor tag and it has an href attribute, add the href attribute to the list of hyperlinks\n",
        "        if tag == \"a\" and \"href\" in attrs:\n",
        "            self.hyperlinks.append(attrs[\"href\"])\n",
        "\n",
        "# Function to get the hyperlinks from a URL\n",
        "def get_hyperlinks(url):\n",
        "    \n",
        "    # Try to open the URL and read the HTML\n",
        "    try:\n",
        "        # Open the URL and read the HTML\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "\n",
        "            # If the response is not HTML, return an empty list\n",
        "            if not response.info().get('Content-Type').startswith(\"text/html\"):\n",
        "                return []\n",
        "            \n",
        "            # Decode the HTML\n",
        "            html = response.read().decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return []\n",
        "\n",
        "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
        "    parser = HyperlinkParser()\n",
        "    parser.feed(html)\n",
        "\n",
        "    return parser.hyperlinks\n",
        "\n",
        "# Function to get the hyperlinks from a URL that are within the same domain\n",
        "def get_domain_hyperlinks(local_domain, url):\n",
        "    clean_links = []\n",
        "    for link in set(get_hyperlinks(url)):\n",
        "        clean_link = None\n",
        "\n",
        "        # If the link is a URL, check if it is within the same domain\n",
        "        if re.search(HTTP_URL_PATTERN, link):\n",
        "            # Parse the URL and check if the domain is the same\n",
        "            url_obj = urlparse(link)\n",
        "            if url_obj.netloc == local_domain:\n",
        "                clean_link = link\n",
        "\n",
        "        # If the link is not a URL, check if it is a relative link\n",
        "        else:\n",
        "            if link.startswith(\"/\"):\n",
        "                link = link[1:]\n",
        "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
        "                continue\n",
        "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
        "\n",
        "        if clean_link is not None:\n",
        "          if (\"crude-oil\" or \"crude_oil\" or \"crude\" and \".cms\") in str(clean_link):\n",
        "            if clean_link.endswith(\"/\"):\n",
        "                clean_link = clean_link[:-1]\n",
        "            clean_links.append(clean_link)\n",
        "\n",
        "    # Return the list of hyperlinks that are within the same domain\n",
        "    return list(set(clean_links))\n",
        "\n",
        "\n",
        "def crawl(url):\n",
        "    # Parse the URL and get the domain\n",
        "    local_domain = urlparse(url).netloc\n",
        "\n",
        "    # Create a queue to store the URLs to crawl\n",
        "    queue = deque([url])\n",
        "\n",
        "    # Create a set to store the URLs that have already been seen (no duplicates)\n",
        "    seen = set([url])\n",
        "\n",
        "    # Create a directory to store the text files\n",
        "    if not os.path.exists(\"text/\"):\n",
        "            os.mkdir(\"text/\")\n",
        "\n",
        "    if not os.path.exists(\"text/\"+local_domain+\"/\"):\n",
        "            os.mkdir(\"text/\" + local_domain + \"/\")\n",
        "\n",
        "    # Create a directory to store the csv files\n",
        "    if not os.path.exists(\"processed\"):\n",
        "            os.mkdir(\"processed\")\n",
        "\n",
        "    # While the queue is not empty, continue crawling\n",
        "    while queue:\n",
        "\n",
        "        # Get the next URL from the queue\n",
        "        url = queue.pop()\n",
        "        print(url) # for debugging and to see the progress\n",
        "\n",
        "        # Save text from the url to a <url>.txt file\n",
        "        with open('text/'+local_domain+'/'+url[8:].replace(\"/\", \"_\") + \".txt\", \"w\") as f:\n",
        "\n",
        "            # Get the text from the URL using BeautifulSoup\n",
        "            soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
        "\n",
        "            # Get the text but remove the tags\n",
        "            text = soup.get_text()\n",
        "\n",
        "            # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
        "            if (\"You need to enable JavaScript to run this app.\" in text):\n",
        "                print(\"Unable to parse page \" + url + \" due to JavaScript being required\")\n",
        "            # Otherwise, write the text to the file in the text directory\n",
        "            f.write(text)\n",
        "\n",
        "        # Get the hyperlinks from the URL and add them to the queue\n",
        "        for link in get_domain_hyperlinks(local_domain, url):\n",
        "            if link not in seen:\n",
        "                queue.append(link)\n",
        "                seen.add(link)\n",
        "\n",
        "crawl(full_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zg1Xi4hJRuo2"
      },
      "outputs": [],
      "source": [
        "def remove_newlines(serie):\n",
        "    serie = serie.str.replace('\\n', ' ')\n",
        "    serie = serie.str.replace('\\\\n', ' ')\n",
        "    serie = serie.str.replace('  ', ' ')\n",
        "    serie = serie.str.replace('  ', ' ')\n",
        "    return serie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "IKX8GXAvRuo2",
        "outputId": "c90735cc-1850-43d8-8387-eec103a9ac20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-429202555403>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  serie = serie.str.replace('\\\\n', ' ')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-827468c1-cef0-4a22-8c20-d0931ce6a7e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>es.indiatimes.com topic crude oil</td>\n",
              "      <td>es.indiatimes.com topic crude oil. crude oil: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>es.indiatimes.com topic why did crude oil pric...</td>\n",
              "      <td>es.indiatimes.com topic why did crude oil pric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>es.indiatimes.com et now commodities crude oil...</td>\n",
              "      <td>es.indiatimes.com et now commodities crude oil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>es.indiatimes.com markets why is crude oil pri...</td>\n",
              "      <td>es.indiatimes.com markets why is crude oil pri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>es.indiatimes.com topic crude oil tax</td>\n",
              "      <td>es.indiatimes.com topic crude oil tax. crude o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-827468c1-cef0-4a22-8c20-d0931ce6a7e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-827468c1-cef0-4a22-8c20-d0931ce6a7e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-827468c1-cef0-4a22-8c20-d0931ce6a7e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               fname  \\\n",
              "0                  es.indiatimes.com topic crude oil   \n",
              "1  es.indiatimes.com topic why did crude oil pric...   \n",
              "2  es.indiatimes.com et now commodities crude oil...   \n",
              "3  es.indiatimes.com markets why is crude oil pri...   \n",
              "4              es.indiatimes.com topic crude oil tax   \n",
              "\n",
              "                                                text  \n",
              "0  es.indiatimes.com topic crude oil. crude oil: ...  \n",
              "1  es.indiatimes.com topic why did crude oil pric...  \n",
              "2  es.indiatimes.com et now commodities crude oil...  \n",
              "3  es.indiatimes.com markets why is crude oil pri...  \n",
              "4  es.indiatimes.com topic crude oil tax. crude o...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list to store the text files\n",
        "texts=[]\n",
        "\n",
        "# Get all the text files in the text directory\n",
        "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
        "\n",
        "    # Open the file and read the text\n",
        "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "        # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
        "        texts.append((file[11:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
        "\n",
        "# Create a dataframe from the list of texts\n",
        "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
        "\n",
        "# Set the text column to be the raw text with the newlines removed\n",
        "df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
        "df.to_csv('processed/scraped.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLuXn0vBUtvB",
        "outputId": "c3c585e4-c05d-4c51-9a2f-662c6ba51384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title       es.indiatimes.com news web stories ipl 2022 ho...\n",
            "text        es.indiatimes.com news web stories ipl 2022 ho...\n",
            "n_tokens                                                  418\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "w7vCwGosRuo2",
        "outputId": "d5df8fd1-16fe-4813-a086-feb74912474e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuitable\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m   2367\u001b[0m         basename = (self.manager.get_window_title() if self.manager is not None\n\u001b[1;32m   2368\u001b[0m                     else '')\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2230\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdots\u001b[0m \u001b[0mper\u001b[0m \u001b[0minch\u001b[0m \u001b[0mto\u001b[0m \u001b[0msave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m         \u001b[0mfacecolor\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfacecolor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m             \u001b[0mfacecolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_PNG\u001b[0m \u001b[0mspecification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2003\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mREC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPNG\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20031110\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m#11keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mpil_kwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mprint_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \"\"\"\n\u001b[1;32m    460\u001b[0m         Draw the canvas, then save it using `.image.imsave` (to which\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0;31m# return MxNx4 RGBA, MxNx3 RBA, or MxN luminance array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I;16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m         \u001b[0;31m# return MxN luminance array of uint16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m             \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m             \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpreinit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;31m#     import TiffImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m#     assert TiffImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;31m# except ImportError:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0;31m#     pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTiffImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi16be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi32be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRational\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTiffTags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi16be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi32be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcontain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \"\"\"\n\u001b[1;32m    244\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mresized\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{old_resampling[name]} or Resampling.{old_resampling[name]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mResampling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold_resampling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'Resampling'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "df = pd.read_csv('processed/scraped.csv', index_col=0)\n",
        "df.columns = ['title', 'text']\n",
        "\n",
        "# Tokenize the text and save the number of tokens to a new column\n",
        "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
        "\n",
        "# Visualize the distribution of the number of tokens per row using a histogram\n",
        "df.n_tokens.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv0otjXRRuo3"
      },
      "outputs": [],
      "source": [
        "max_tokens = 500\n",
        "\n",
        "# Function to split the text into chunks of a maximum number of tokens\n",
        "def split_into_many(text, max_tokens = max_tokens):\n",
        "\n",
        "    # Split the text into sentences\n",
        "    sentences = text.split('. ')\n",
        "\n",
        "    # Get the number of tokens for each sentence\n",
        "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
        "    \n",
        "    chunks = []\n",
        "    tokens_so_far = 0\n",
        "    chunk = []\n",
        "\n",
        "    # Loop through the sentences and tokens joined together in a tuple\n",
        "    for sentence, token in zip(sentences, n_tokens):\n",
        "\n",
        "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
        "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
        "        # the chunk and tokens so far\n",
        "        if tokens_so_far + token > max_tokens:\n",
        "            chunks.append(\". \".join(chunk) + \".\")\n",
        "            chunk = []\n",
        "            tokens_so_far = 0\n",
        "\n",
        "        # If the number of tokens in the current sentence is greater than the max number of \n",
        "        # tokens, go to the next sentence\n",
        "        if token > max_tokens:\n",
        "            continue\n",
        "\n",
        "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
        "        chunk.append(sentence)\n",
        "        tokens_so_far += token + 1\n",
        "\n",
        "    return chunks\n",
        "    \n",
        "\n",
        "shortened = []\n",
        "\n",
        "# Loop through the dataframe\n",
        "for row in df.iterrows():\n",
        "\n",
        "    # If the text is None, go to the next row\n",
        "    if row[1]['text'] is None:\n",
        "        continue\n",
        "\n",
        "    # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
        "    if row[1]['n_tokens'] > max_tokens:\n",
        "        shortened += split_into_many(row[1]['text'])\n",
        "    \n",
        "    # Otherwise, add the text to the list of shortened texts\n",
        "    else:\n",
        "        shortened.append( row[1]['text'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCmP--iSRuo3",
        "outputId": "bed3210d-0a6b-4f34-af95-47589cbf2c3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame(shortened, columns = ['text'])\n",
        "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
        "df.n_tokens.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC_PgeSdRuo3",
        "outputId": "3cf45744-00dd-4a0b-a929-74cafaccf449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blog authors maddie.   Maddie Hall - OpenAI   ...</td>\n",
              "      <td>175</td>\n",
              "      <td>[-0.012958061881363392, -0.006103983614593744,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blog authors tom.   Tom Brown - OpenAI        ...</td>\n",
              "      <td>228</td>\n",
              "      <td>[-0.0053874170407652855, -0.009962032549083233...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blog openai scholars 2019 final projects.   Op...</td>\n",
              "      <td>492</td>\n",
              "      <td>[0.0019150723237544298, -0.0070442273281514645...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this project, I used curiosity-driven explo...</td>\n",
              "      <td>478</td>\n",
              "      <td>[-0.0067560747265815735, 0.0004431474662851542...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Results revealed that the optimal RL policies ...</td>\n",
              "      <td>499</td>\n",
              "      <td>[-0.012868616729974747, 0.0029640409629791975,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  n_tokens  \\\n",
              "0  blog authors maddie.   Maddie Hall - OpenAI   ...       175   \n",
              "1  blog authors tom.   Tom Brown - OpenAI        ...       228   \n",
              "2  blog openai scholars 2019 final projects.   Op...       492   \n",
              "3  In this project, I used curiosity-driven explo...       478   \n",
              "4  Results revealed that the optimal RL policies ...       499   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.012958061881363392, -0.006103983614593744,...  \n",
              "1  [-0.0053874170407652855, -0.009962032549083233...  \n",
              "2  [0.0019150723237544298, -0.0070442273281514645...  \n",
              "3  [-0.0067560747265815735, 0.0004431474662851542...  \n",
              "4  [-0.012868616729974747, 0.0029640409629791975,...  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
        "df.to_csv('processed/embeddings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ8366omRuo4",
        "outputId": "d8fea2cf-78ef-4c2d-cb7f-7a5cbc79912a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blog authors maddie.   Maddie Hall - OpenAI   ...</td>\n",
              "      <td>175</td>\n",
              "      <td>[-0.012958061881363392, -0.006103983614593744,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blog authors tom.   Tom Brown - OpenAI        ...</td>\n",
              "      <td>228</td>\n",
              "      <td>[-0.0053874170407652855, -0.009962032549083233...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blog openai scholars 2019 final projects.   Op...</td>\n",
              "      <td>492</td>\n",
              "      <td>[0.0019150723237544298, -0.0070442273281514645...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this project, I used curiosity-driven explo...</td>\n",
              "      <td>478</td>\n",
              "      <td>[-0.0067560747265815735, 0.0004431474662851542...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Results revealed that the optimal RL policies ...</td>\n",
              "      <td>499</td>\n",
              "      <td>[-0.012868616729974747, 0.0029640409629791975,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  n_tokens  \\\n",
              "0  blog authors maddie.   Maddie Hall - OpenAI   ...       175   \n",
              "1  blog authors tom.   Tom Brown - OpenAI        ...       228   \n",
              "2  blog openai scholars 2019 final projects.   Op...       492   \n",
              "3  In this project, I used curiosity-driven explo...       478   \n",
              "4  Results revealed that the optimal RL policies ...       499   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.012958061881363392, -0.006103983614593744,...  \n",
              "1  [-0.0053874170407652855, -0.009962032549083233...  \n",
              "2  [0.0019150723237544298, -0.0070442273281514645...  \n",
              "3  [-0.0067560747265815735, 0.0004431474662851542...  \n",
              "4  [-0.012868616729974747, 0.0029640409629791975,...  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai.embeddings_utils import distances_from_embeddings\n",
        "\n",
        "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
        "\n",
        "df.to_csv('processed/embeddings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJcuiCo0Ruo4",
        "outputId": "0d983a5d-ec20-4f53-fb81-1fb0cd3651b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blog authors maddie.   Maddie Hall - OpenAI   ...</td>\n",
              "      <td>175</td>\n",
              "      <td>[-0.012958061881363392, -0.006103983614593744,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blog authors tom.   Tom Brown - OpenAI        ...</td>\n",
              "      <td>228</td>\n",
              "      <td>[-0.0053874170407652855, -0.009962032549083233...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blog openai scholars 2019 final projects.   Op...</td>\n",
              "      <td>492</td>\n",
              "      <td>[0.0019150723237544298, -0.0070442273281514645...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this project, I used curiosity-driven explo...</td>\n",
              "      <td>478</td>\n",
              "      <td>[-0.0067560747265815735, 0.0004431474662851542...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Results revealed that the optimal RL policies ...</td>\n",
              "      <td>499</td>\n",
              "      <td>[-0.012868616729974747, 0.0029640409629791975,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  n_tokens  \\\n",
              "0  blog authors maddie.   Maddie Hall - OpenAI   ...       175   \n",
              "1  blog authors tom.   Tom Brown - OpenAI        ...       228   \n",
              "2  blog openai scholars 2019 final projects.   Op...       492   \n",
              "3  In this project, I used curiosity-driven explo...       478   \n",
              "4  Results revealed that the optimal RL policies ...       499   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.012958061881363392, -0.006103983614593744,...  \n",
              "1  [-0.0053874170407652855, -0.009962032549083233...  \n",
              "2  [0.0019150723237544298, -0.0070442273281514645...  \n",
              "3  [-0.0067560747265815735, 0.0004431474662851542...  \n",
              "4  [-0.012868616729974747, 0.0029640409629791975,...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openai.embeddings_utils import distances_from_embeddings, cosine_similarity\n",
        "\n",
        "df=pd.read_csv('processed/embeddings.csv', index_col=0)\n",
        "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeQlTfrRRuo4",
        "outputId": "cf4245cb-a052-4841-8011-7c5e088bbc98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'No, you are not allowed to publish model outputs to Twitter without a human review. You must manually review each generation before sharing or while streaming, and indicate that the content is AI-generated in a way no user could reasonably miss or misunderstand.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_context(\n",
        "    question, df, max_len=1800, size=\"ada\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a context for a question by finding the most similar context from the dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the embeddings for the question\n",
        "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
        "\n",
        "    # Get the distances from the embeddings\n",
        "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
        "\n",
        "\n",
        "    returns = []\n",
        "    cur_len = 0\n",
        "\n",
        "    # Sort by distance and add the text to the context until the context is too long\n",
        "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
        "        \n",
        "        # Add the length of the text to the current length\n",
        "        cur_len += row['n_tokens'] + 4\n",
        "        \n",
        "        # If the context is too long, break\n",
        "        if cur_len > max_len:\n",
        "            break\n",
        "        \n",
        "        # Else add it to the text that is being returned\n",
        "        returns.append(row[\"text\"])\n",
        "\n",
        "    # Return the context\n",
        "    return \"\\n\\n###\\n\\n\".join(returns)\n",
        "\n",
        "def answer_question(\n",
        "    df,\n",
        "    model=\"text-davinci-003\",\n",
        "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
        "    max_len=1800,\n",
        "    size=\"ada\",\n",
        "    debug=False,\n",
        "    max_tokens=150,\n",
        "    stop_sequence=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Answer a question based on the most similar context from the dataframe texts\n",
        "    \"\"\"\n",
        "    context = create_context(\n",
        "        question,\n",
        "        df,\n",
        "        max_len=max_len,\n",
        "        size=size,\n",
        "    )\n",
        "    # If debug, print the raw model response\n",
        "    if debug:\n",
        "        print(\"Context:\\n\" + context)\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "    try:\n",
        "        # Create a completions using the question and context\n",
        "        response = openai.Completion.create(\n",
        "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            stop=stop_sequence,\n",
        "            model=model,\n",
        "        )\n",
        "        return response[\"choices\"][0][\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvueE_4lRuo5",
        "outputId": "13c1682e-0840-4968-f0e8-eb87c5dc37a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_question(df, question=\"What day is it?\", debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54PWskW_Ruo5",
        "outputId": "0ec2be44-9663-4f72-8520-1b9ffa636ee6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The newest embeddings model is text-embedding-ada-002.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_question(df, question=\"What is our newest embeddings model?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "05f34a34d73b71652304030c1097be3a5720ea2447153dd6542d145a26b73181"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
